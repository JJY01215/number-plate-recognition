# -*- coding: utf-8 -*-
"""機器學習-車牌.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1BxykuN33jn2ztN8dqeQTBhp-Xfh_zEUy
"""

#訓練-3
# 訓練 - 改善過擬合版本
import os
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger, TensorBoard, ReduceLROnPlateau
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from google.colab import drive

# 掛載 Google Drive
drive.mount('/content/drive')

# GPU 檢查
print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# 目錄設定
base_dir = '/content/drive/MyDrive/model_training'
checkpoint_dir = os.path.join(base_dir, 'checkpoints')
log_dir = os.path.join(base_dir, 'logs')
dataset_dir = os.path.join(base_dir, 'dataset')
os.makedirs(checkpoint_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(dataset_dir, exist_ok=True)

# 資料增強
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    horizontal_flip=True,
    fill_mode='nearest'
)
val_datagen = ImageDataGenerator(rescale=1./255)

# 載入資料
train_generator = train_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'train'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)
val_generator = val_datagen.flow_from_directory(
    os.path.join(dataset_dir, 'validation'),
    target_size=(224, 224),
    batch_size=32,
    class_mode='categorical'
)

# 建立模型
base_model = ResNet50(weights='imagenet', include_top=False)
for layer in base_model.layers:
    layer.trainable = False  # 凍結 ResNet50 卷積層

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dense(1024, activation='relu')(x)
predictions = Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=base_model.input, outputs=predictions)

# 編譯模型（較小學習率）
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# 回調函數
checkpoint = ModelCheckpoint(
    filepath=os.path.join(checkpoint_dir, 'model_best.h5'),
    monitor='val_loss',
    save_best_only=True,
    mode='min',
    verbose=1
)

early_stopping = EarlyStopping(
    monitor='val_loss',
    patience=5,
    restore_best_weights=True,
    verbose=1
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=2,
    min_lr=1e-6,
    verbose=1
)

csv_logger = CSVLogger(os.path.join(log_dir, 'training_history.csv'), separator=',', append=False)

tensorboard = TensorBoard(log_dir=os.path.join(log_dir, 'tensorboard'), histogram_freq=1)

# 開始訓練
history = model.fit(
    train_generator,
    epochs=5,
    validation_data=val_generator,
    callbacks=[checkpoint, early_stopping, csv_logger, tensorboard, reduce_lr],
    verbose=1
)

# 儲存最終模型
model.save(os.path.join(checkpoint_dir, 'model_final.h5'))
print("訓練完成！模型已儲存。")

# 視覺化訓練結果
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()

plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend()
plt.grid(True)
plt.show()