import cv2
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import pyocr
import pyocr.builders
import re
import sys
import time
import os
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import TextSendMessage

# å¼•å…¥ Google Sheets API æ¨¡çµ„
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

# å¾ç’°å¢ƒè®Šæ•¸ç²å– LINE Bot Token å’Œ Secret
LINE_CHANNEL_ACCESS_TOKEN = os.getenv('LINE_CHANNEL_ACCESS_TOKEN')  # LINE access token
LINE_CHANNEL_SECRET = os.getenv('LINE_CHANNEL_SECRET')  # LINE secret

# å¾ç’°å¢ƒè®Šæ•¸ç²å– Google Sheets API é‡‘é‘°
GOOGLE_SHEET_CREDENTIALS_FILE = os.getenv('GOOGLE_SHEET_CREDENTIALS_FILE')  # Google Sheets API credential file

# åˆå§‹åŒ– OCR å·¥å…·
tools = pyocr.get_available_tools()
if len(tools) == 0:
    print("âŒ No OCR tool found")
    sys.exit(1)
tool = tools[0]

# ç”¨ä¾†åµæ¸¬è»Šç‰Œçš„ Haar åˆ†é¡å™¨
detector = cv2.CascadeClassifier('haar_carplate.xml')

# è®€å– Google Sheets çš„è»Šè¼›è³‡æ–™
def load_vehicle_data_from_sheets(spreadsheet_id, range_name):
    # æˆæ¬Š
    credentials = Credentials.from_service_account_file(
        GOOGLE_SHEET_CREDENTIALS_FILE, scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"]
    )
    service = build('sheets', 'v4', credentials=credentials)

    # è®€å–è³‡æ–™
    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()
    values = result.get('values', [])
    if not values:
        print("No data found.")
        return None
    else:
        # å°‡è³‡æ–™è½‰æ›æˆ DataFrame æ ¼å¼
        import pandas as pd
        df = pd.DataFrame(values[1:], columns=values[0])
        return df

# æŸ¥è©¢è»Šè¼›è³‡è¨Š
def get_vehicle_info(plate_number, vehicle_data):
    vehicle_info = vehicle_data[vehicle_data['è»Šç‰Œè™Ÿç¢¼'] == plate_number]
    if not vehicle_info.empty:
        return vehicle_info.iloc[0]
    else:
        return None

def remove_noise_and_segment(thresh):
    contours1 = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = contours1[0]
    letter_image_regions = []
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if x >= 2 and x <= 125 and w >= 5 and w <= 35 and h >= 20 and h < 40:
            letter_image_regions.append((x, y, w, h))
    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])
    return letter_image_regions

def extract_characters(thresh, letterlist):
    real_shape = []
    for i, box in enumerate(letterlist):
        x, y, w, h = box
        bg = thresh[y:y+h, x:x+w]
        real_shape.append(bg)
    return real_shape

def reconstruct_plate_image(thresh, letterlist, real_shape):
    newH, newW = thresh.shape
    space = 10
    bg = np.zeros((newH + space*2, newW + space*2 + 20, 1), np.uint8)
    bg.fill(0)
    for i, letter in enumerate(real_shape):
        h = letter.shape[0]
        w = letter.shape[1]
        x = letterlist[i][0]
        y = letterlist[i][1]
        for row in range(h):
            for col in range(w):
                bg[space + y + row][space + x + col + i*3] = letter[row][col]
    _, bg = cv2.threshold(bg, 127, 255, cv2.THRESH_BINARY_INV)
    return bg

def ocr_recognition(image_path='result.jpg'):
    result = tool.image_to_string(
        Image.open(image_path),
        builder=pyocr.builders.TextBuilder()
    )
    txt = result.replace("!", "1")
    real_txt = re.findall(r'[A-Z]+|[\d]+', txt)
    txt_plate = "".join(real_txt)
    return txt, txt_plate

# LINE Bot è¨­å®š
line_bot_api = LineBotApi(LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)
your_user_id = os.getenv('LINE_USER_ID')  # å¾ç’°å¢ƒè®Šæ•¸ç²å– LINE ä½¿ç”¨è€… ID

# Flask åˆå§‹åŒ–
app = Flask(__name__)

# æ¥æ”¶ LINE Webhook çš„ç«¯é»
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# è¨­å®šä¸­æ–‡å­—å‹
font_path = "C:/Windows/Fonts/msjh.ttc"
font = ImageFont.truetype(font_path, 36)

# å•Ÿå‹•æ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

# è»Šä¸»è³‡è¨Šè¨˜éŒ„
last_detection_time = 0
car_owner = ""
detection_in_progress = False

print("ğŸ“· é–‹å§‹å¾æ”å½±æ©Ÿæ“·å–ç•«é¢é€²è¡Œè»Šç‰Œè¾¨è­˜...ï¼ˆæŒ‰ q çµæŸï¼‰")

# è®€å–è»Šè¼›è³‡æ–™ Google Sheets ID å’Œç¯„åœ
spreadsheet_id = '1gM7sqVtmsB880hdUFGdL3gltlGtCWPFRLSOdTGgyZsM'
range_name = 'å·¥ä½œè¡¨1!A1:B100' # å‡è¨­è³‡æ–™ç¯„åœæ˜¯å¾ A1 åˆ° D æ¬„

# è®€å– Google Sheets çš„è»Šè¼›è³‡æ–™
vehicle_data = load_vehicle_data_from_sheets(spreadsheet_id, range_name)

# ä¸»è¿´åœˆ
while True:
    ret, frame = cap.read()
    if not ret:
        break

    if detection_in_progress and (time.time() - last_detection_time < 10):
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)
        draw.text((50, 50), f"è»Šä¸»ï¼š{car_owner}", font=font, fill=(0, 255, 0))
        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

        cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    signs = detector.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=4, minSize=(20, 20))
    result_img = None
    for (x, y, w, h) in signs:
        plate = frame[y:y+h, x:x+w]
        plate_pil = Image.fromarray(plate).resize((140, 40), Image.ANTIALIAS)
        plate_gray = np.array(plate_pil.convert('L'))
        _, thresh = cv2.threshold(plate_gray, 127, 255, cv2.THRESH_BINARY_INV)

        letterlist = remove_noise_and_segment(thresh)
        if len(letterlist) == 0:
            continue
        real_shape = extract_characters(thresh, letterlist)
        result_img = reconstruct_plate_image(thresh, letterlist, real_shape)
        cv2.imwrite('result.jpg', result_img)
        break

    if result_img is not None:
        txt, txt_plate = ocr_recognition('result.jpg')
        print("ğŸ”¤ åŸå§‹è¾¨è­˜ï¼š", txt)
        print("âœ… å„ªåŒ–çµæœï¼š", txt_plate)

        vehicle_info = get_vehicle_info(txt_plate, vehicle_data)
        if vehicle_info is not None:
            car_owner = vehicle_info['è»Šä¸»å§“å']
            last_detection_time = time.time()
            detection_in_progress = True

            # ç™¼é€è¨Šæ¯åˆ° LINE
            line_bot_api.push_message(your_user_id, TextSendMessage(text=f"ğŸš— åµæ¸¬åˆ°è»Šä¸»ï¼š{car_owner}\nğŸ”¢ è»Šç‰Œè™Ÿç¢¼ï¼š{txt_plate}"))

    cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
