import cv2
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import pyocr
import pyocr.builders
import re
import sys
import time
import os
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import TextSendMessage

from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build

# è¼‰å…¥ .env ç’°å¢ƒè®Šæ•¸
from dotenv import load_dotenv
load_dotenv()

# åˆå§‹åŒ– OCR å·¥å…·
tools = pyocr.get_available_tools()
if len(tools) == 0:
    print("âŒ No OCR tool found")
    sys.exit(1)
tool = tools[0]

# ç”¨ä¾†åµæ¸¬è»Šç‰Œçš„ Haar åˆ†é¡å™¨
detector = cv2.CascadeClassifier('haar_carplate.xml')

# è®€å– Google Sheets çš„è»Šè¼›è³‡æ–™
def load_vehicle_data_from_sheets(spreadsheet_id, range_name):
    credentials = Credentials.from_service_account_file(
        os.getenv("GOOGLE_CREDENTIALS_PATH"), 
        scopes=["https://www.googleapis.com/auth/spreadsheets.readonly"]
    )
    service = build('sheets', 'v4', credentials=credentials)
    sheet = service.spreadsheets()
    result = sheet.values().get(spreadsheetId=spreadsheet_id, range=range_name).execute()
    values = result.get('values', [])
    if not values:
        print("No data found.")
        return None
    else:
        import pandas as pd
        df = pd.DataFrame(values[1:], columns=values[0])
        return df

# æŸ¥è©¢è»Šä¸»è³‡æ–™
def get_vehicle_info(plate_number, vehicle_data):
    vehicle_info = vehicle_data[vehicle_data['è»Šç‰Œè™Ÿç¢¼'] == plate_number]
    if not vehicle_info.empty:
        return vehicle_info.iloc[0]
    else:
        return None

def remove_noise_and_segment(thresh):
    contours1 = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = contours1[0]
    letter_image_regions = []
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if x >= 2 and x <= 125 and w >= 5 and w <= 35 and h >= 20 and h < 40:
            letter_image_regions.append((x, y, w, h))
    return sorted(letter_image_regions, key=lambda x: x[0])

def extract_characters(thresh, letterlist):
    return [thresh[y:y+h, x:x+w] for (x, y, w, h) in letterlist]

def reconstruct_plate_image(thresh, letterlist, real_shape):
    newH, newW = thresh.shape
    space = 10
    bg = np.zeros((newH + space*2, newW + space*2 + 20, 1), np.uint8)
    bg.fill(0)
    for i, letter in enumerate(real_shape):
        h, w = letter.shape
        x, y = letterlist[i][0], letterlist[i][1]
        for row in range(h):
            for col in range(w):
                bg[space + y + row][space + x + col + i*3] = letter[row][col]
    _, bg = cv2.threshold(bg, 127, 255, cv2.THRESH_BINARY_INV)
    return bg

def ocr_recognition(image_path='result.jpg'):
    result = tool.image_to_string(
        Image.open(image_path),
        builder=pyocr.builders.TextBuilder()
    )
    txt = result.replace("!", "1")
    real_txt = re.findall(r'[A-Z]+|[\d]+', txt)
    txt_plate = "".join(real_txt)
    return txt, txt_plate

# LINE Bot è¨­å®š
line_bot_api = LineBotApi(os.getenv("LINE_CHANNEL_ACCESS_TOKEN"))
handler = WebhookHandler(os.getenv("LINE_CHANNEL_SECRET"))
your_user_id = os.getenv("LINE_USER_ID")

# Flask åˆå§‹åŒ–
app = Flask(__name__)

@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# å­—å‹è¨­å®š
font_path = os.getenv("FONT_PATH", "C:/Windows/Fonts/msjh.ttc")
font = ImageFont.truetype(font_path, 36)

# é–‹å•Ÿæ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

# è»Šä¸»è³‡è¨Šè¨˜éŒ„
last_detection_time = 0
car_owner = ""
detection_in_progress = False

print("ğŸ“· é–‹å§‹å¾æ”å½±æ©Ÿæ“·å–ç•«é¢é€²è¡Œè»Šç‰Œè¾¨è­˜...ï¼ˆæŒ‰ q çµæŸï¼‰")

# è®€å–è»Šè¼›è³‡æ–™
spreadsheet_id = os.getenv("GOOGLE_SHEET_ID")
range_name = 'å·¥ä½œè¡¨1!A1:B100'
vehicle_data = load_vehicle_data_from_sheets(spreadsheet_id, range_name)

# ä¸»è¿´åœˆ
while True:
    ret, frame = cap.read()
    if not ret:
        break

    if detection_in_progress and (time.time() - last_detection_time < 10):
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)
        draw.text((50, 50), f"è»Šä¸»ï¼š{car_owner}", font=font, fill=(0, 255, 0))
        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)
        cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    signs = detector.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=4, minSize=(20, 20))
    result_img = None
    for (x, y, w, h) in signs:
        plate = frame[y:y+h, x:x+w]
        plate_pil = Image.fromarray(plate).resize((140, 40), Image.ANTIALIAS)
        plate_gray = np.array(plate_pil.convert('L'))
        _, thresh = cv2.threshold(plate_gray, 127, 255, cv2.THRESH_BINARY_INV)

        letterlist = remove_noise_and_segment(thresh)
        if len(letterlist) == 0:
            continue
        real_shape = extract_characters(thresh, letterlist)
        result_img = reconstruct_plate_image(thresh, letterlist, real_shape)
        cv2.imwrite('result.jpg', result_img)
        break

    if result_img is not None:
        txt, txt_plate = ocr_recognition('result.jpg')
        print("ğŸ”¤ åŸå§‹è¾¨è­˜ï¼š", txt)
        print("âœ… å„ªåŒ–çµæœï¼š", txt_plate)

        vehicle_info = get_vehicle_info(txt_plate, vehicle_data)
        if vehicle_info is not None:
            car_owner = vehicle_info['è»Šä¸»å§“å']
            last_detection_time = time.time()
            detection_in_progress = True

            line_bot_api.push_message(your_user_id, TextSendMessage(text=f"ğŸš— åµæ¸¬åˆ°è»Šä¸»ï¼š{car_owner}"))

    cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
