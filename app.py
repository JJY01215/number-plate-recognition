# -*- coding: utf-8 -*-
import cv2
import numpy as np
from PIL import Image, ImageFont, ImageDraw
import pyocr
import pyocr.builders
import re
import os
import sys
import pandas as pd
import time
from flask import Flask, request, abort
from linebot import LineBotApi, WebhookHandler
from linebot.exceptions import InvalidSignatureError
from linebot.models import TextSendMessage

# åˆå§‹åŒ– OCR å·¥å…·
tools = pyocr.get_available_tools()
if len(tools) == 0:
    print("âŒ No OCR tool found")
    sys.exit(1)
tool = tools[0]

# ç”¨ä¾†åµæ¸¬è»Šç‰Œçš„ Haar åˆ†é¡å™¨
detector = cv2.CascadeClassifier('haar_carplate.xml')

# è®€å– CSV æª”æ¡ˆ
def load_vehicle_data(csv_file='vehicle_data.csv'):
    return pd.read_csv(csv_file)

# æŸ¥è©¢è»Šè¼›è³‡è¨Š
def get_vehicle_info(plate_number, vehicle_data):
    vehicle_info = vehicle_data[vehicle_data['è»Šç‰Œè™Ÿç¢¼'] == plate_number]
    if not vehicle_info.empty:
        return vehicle_info.iloc[0]
    else:
        return None

def remove_noise_and_segment(thresh):
    contours1 = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = contours1[0]
    letter_image_regions = []
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if x >= 2 and x <= 125 and w >= 5 and w <= 35 and h >= 20 and h < 40:
            letter_image_regions.append((x, y, w, h))
    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])
    return letter_image_regions

def extract_characters(thresh, letterlist):
    real_shape = []
    for i, box in enumerate(letterlist):
        x, y, w, h = box
        bg = thresh[y:y+h, x:x+w]
        real_shape.append(bg)
    return real_shape

def reconstruct_plate_image(thresh, letterlist, real_shape):
    newH, newW = thresh.shape
    space = 10
    bg = np.zeros((newH + space*2, newW + space*2 + 20, 1), np.uint8)
    bg.fill(0)
    for i, letter in enumerate(real_shape):
        h = letter.shape[0]
        w = letter.shape[1]
        x = letterlist[i][0]
        y = letterlist[i][1]
        for row in range(h):
            for col in range(w):
                bg[space + y + row][space + x + col + i*3] = letter[row][col]
    _, bg = cv2.threshold(bg, 127, 255, cv2.THRESH_BINARY_INV)
    return bg

def ocr_recognition(image_path='result.jpg'):
    result = tool.image_to_string(
        Image.open(image_path),
        builder=pyocr.builders.TextBuilder()
    )
    txt = result.replace("!", "1")
    real_txt = re.findall(r'[A-Z]+|[\d]+', txt)
    txt_plate = "".join(real_txt)
    return txt, txt_plate

# è®€å–è»Šè¼›è³‡æ–™ CSV
vehicle_data = load_vehicle_data('vehicle_data.csv')

# LINE Bot è¨­å®šï¼ˆè¨˜å¾—å¡«å…¥ä½ è‡ªå·±çš„ token å’Œ secretï¼‰
line_bot_api = LineBotApi('uFHbI+8o1U8yez1l+XeX49ApmXY59K7WKkqVFbxpBvsZwLBXaHKxs1ai/R4S5a4yAWED+m+lsSNvEkVks8Io7Y1c3XDEXLH4YpsrVJcNkjKfxmaTAmdjMYTLFIU6CBS9fGBl693+DiVH4/pamNdxOwdB04t89/1O/w1cDnyilFU=')
handler = WebhookHandler('de7491351d0c4f906259d352df34e63a')
your_user_id = 'U932c52b32c3de90e108da3e55af77548'  # é€™è£¡è«‹å¡«å…¥ä½ è‡ªå·±çš„ LINE ä½¿ç”¨è€… ID

# Flask åˆå§‹åŒ–
app = Flask(__name__)

# æ¥æ”¶ LINE Webhook çš„ç«¯é»
@app.route("/callback", methods=['POST'])
def callback():
    signature = request.headers['X-Line-Signature']
    body = request.get_data(as_text=True)
    try:
        handler.handle(body, signature)
    except InvalidSignatureError:
        abort(400)
    return 'OK'

# è¨­å®šä¸­æ–‡å­—å‹
font_path = "C:/Windows/Fonts/msjh.ttc"
font = ImageFont.truetype(font_path, 36)

# å•Ÿå‹•æ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

# è»Šä¸»è³‡è¨Šè¨˜éŒ„
last_detection_time = 0
car_owner = ""
detection_in_progress = False

print("ğŸ“· é–‹å§‹å¾æ”å½±æ©Ÿæ“·å–ç•«é¢é€²è¡Œè»Šç‰Œè¾¨è­˜...ï¼ˆæŒ‰ q çµæŸï¼‰")

# ä¸»è¿´åœˆ
while True:
    ret, frame = cap.read()
    if not ret:
        break

    if detection_in_progress and (time.time() - last_detection_time < 10):
        frame_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(frame_pil)
        draw.text((50, 50), f"è»Šä¸»ï¼š{car_owner}", font=font, fill=(0, 255, 0))
        frame = cv2.cvtColor(np.array(frame_pil), cv2.COLOR_RGB2BGR)

        cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    signs = detector.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=4, minSize=(20, 20))
    result_img = None
    for (x, y, w, h) in signs:
        plate = frame[y:y+h, x:x+w]
        plate_pil = Image.fromarray(plate).resize((140, 40), Image.ANTIALIAS)
        plate_gray = np.array(plate_pil.convert('L'))
        _, thresh = cv2.threshold(plate_gray, 127, 255, cv2.THRESH_BINARY_INV)

        letterlist = remove_noise_and_segment(thresh)
        if len(letterlist) == 0:
            continue
        real_shape = extract_characters(thresh, letterlist)
        result_img = reconstruct_plate_image(thresh, letterlist, real_shape)
        cv2.imwrite('result.jpg', result_img)
        break

    if result_img is not None:
        txt, txt_plate = ocr_recognition('result.jpg')
        print("ğŸ”¤ åŸå§‹è¾¨è­˜ï¼š", txt)
        print("âœ… å„ªåŒ–çµæœï¼š", txt_plate)

        vehicle_info = get_vehicle_info(txt_plate, vehicle_data)
        if vehicle_info is not None:
            car_owner = vehicle_info['è»Šä¸»å§“å']
            last_detection_time = time.time()
            detection_in_progress = True

            # ç™¼é€è¨Šæ¯åˆ° LINE
            line_bot_api.push_message(your_user_id, TextSendMessage(text=f"ğŸš— åµæ¸¬åˆ°è»Šä¸»ï¼š{car_owner}"))

    cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
