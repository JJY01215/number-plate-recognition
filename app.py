# -*- coding: utf-8 -*-
"""2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EEJ62cr78JJMWW8g1vx8sjRvU77f1xQk
"""

import cv2
import numpy as np
from PIL import Image
import pyocr
import pyocr.builders
import re
import os
import sys
import pandas as pd
import time  # åŠ å…¥æ™‚é–“æ¨¡çµ„

# åˆå§‹åŒ– OCR å·¥å…·
tools = pyocr.get_available_tools()
if len(tools) == 0:
    print("âŒ No OCR tool found")
    sys.exit(1)
tool = tools[0]

# ç”¨ä¾†åµæ¸¬è»Šç‰Œçš„ Haar åˆ†é¡å™¨
detector = cv2.CascadeClassifier('haar_carplate.xml')

# è®€å– CSV æª”æ¡ˆ
def load_vehicle_data(csv_file='vehicle_data.csv'):
    # ä½¿ç”¨ pandas è®€å– CSV
    return pd.read_csv(csv_file)

# æŸ¥è©¢è»Šè¼›è³‡è¨Š
def get_vehicle_info(plate_number, vehicle_data):
    # æ ¹æ“šè»Šç‰Œè™Ÿç¢¼æŸ¥è©¢
    vehicle_info = vehicle_data[vehicle_data['è»Šç‰Œè™Ÿç¢¼'] == plate_number]
    if not vehicle_info.empty:
        # æå–è»Šè¼›è³‡æ–™
        return vehicle_info.iloc[0]
    else:
        return None

def remove_noise_and_segment(thresh):
    contours1 = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    contours = contours1[0]
    letter_image_regions = []
    for contour in contours:
        (x, y, w, h) = cv2.boundingRect(contour)
        if x >= 2 and x <= 125 and w >= 5 and w <= 35 and h >= 20 and h < 40:
            letter_image_regions.append((x, y, w, h))
    letter_image_regions = sorted(letter_image_regions, key=lambda x: x[0])
    return letter_image_regions

def extract_characters(thresh, letterlist):
    real_shape = []
    for i, box in enumerate(letterlist):
        x, y, w, h = box
        bg = thresh[y:y+h, x:x+w]
        real_shape.append(bg)
    return real_shape

def reconstruct_plate_image(thresh, letterlist, real_shape):
    newH, newW = thresh.shape
    space = 10
    bg = np.zeros((newH + space*2, newW + space*2 + 20, 1), np.uint8)
    bg.fill(0)
    for i, letter in enumerate(real_shape):
        h = letter.shape[0]
        w = letter.shape[1]
        x = letterlist[i][0]
        y = letterlist[i][1]
        for row in range(h):
            for col in range(w):
                bg[space + y + row][space + x + col + i*3] = letter[row][col]
    _, bg = cv2.threshold(bg, 127, 255, cv2.THRESH_BINARY_INV)
    return bg

def ocr_recognition(image_path='result.jpg'):
    result = tool.image_to_string(
        Image.open(image_path),
        builder=pyocr.builders.TextBuilder()
    )
    txt = result.replace("!", "1")
    real_txt = re.findall(r'[A-Z]+|[\d]+', txt)
    txt_plate = "".join(real_txt)
    return txt, txt_plate

# è®€å–è»Šè¼›è³‡æ–™ CSV
vehicle_data = load_vehicle_data('vehicle_data.csv')

# å•Ÿå‹•æ”å½±æ©Ÿ
cap = cv2.VideoCapture(0)

# è¨˜éŒ„ä¸Šæ¬¡é¡¯ç¤ºè»Šä¸»åå­—çš„æ™‚é–“
last_detection_time = 0
car_owner = ""
detection_in_progress = False  # åµæ¸¬æ˜¯å¦é€²è¡Œä¸­

print("ğŸ“· é–‹å§‹å¾æ”å½±æ©Ÿæ“·å–ç•«é¢é€²è¡Œè»Šç‰Œè¾¨è­˜...ï¼ˆæŒ‰ q çµæŸï¼‰")
while True:
    ret, frame = cap.read()
    if not ret:
        break

    # å¦‚æœåµæ¸¬å·²ç¶“é€²è¡Œéä¸”ä¸åˆ°10ç§’ï¼Œä¸é€²è¡Œåµæ¸¬
    if detection_in_progress and (time.time() - last_detection_time < 10):
        # é¡¯ç¤ºè»Šä¸»åå­—
        cv2.putText(frame, f"è»Šä¸»: {car_owner}", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
        continue

    # é–‹å§‹åµæ¸¬è»Šç‰Œ
    signs = detector.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=4, minSize=(20, 20))
    result_img = None
    for (x, y, w, h) in signs:
        plate = frame[y:y+h, x:x+w]
        plate_pil = Image.fromarray(plate).resize((140, 40), Image.ANTIALIAS)
        plate_gray = np.array(plate_pil.convert('L'))
        _, thresh = cv2.threshold(plate_gray, 127, 255, cv2.THRESH_BINARY_INV)

        letterlist = remove_noise_and_segment(thresh)
        if len(letterlist) == 0:
            continue
        real_shape = extract_characters(thresh, letterlist)
        result_img = reconstruct_plate_image(thresh, letterlist, real_shape)
        cv2.imwrite('result.jpg', result_img)
        break  # ä¸€æ¬¡è™•ç†ä¸€å¼µè»Šç‰Œ

    if result_img is not None:
        txt, txt_plate = ocr_recognition('result.jpg')
        print("ğŸ”¤ åŸå§‹è¾¨è­˜ï¼š", txt)
        print("âœ… å„ªåŒ–çµæœï¼š", txt_plate)

        # æ ¹æ“šè»Šç‰Œè™Ÿç¢¼æŸ¥è©¢è»Šè¼›è³‡è¨Š
        vehicle_info = get_vehicle_info(txt_plate, vehicle_data)
        if vehicle_info is not None:
            car_owner = vehicle_info['è»Šä¸»å§“å']  # å–å¾—è»Šä¸»å§“å
            last_detection_time = time.time()  # è¨˜éŒ„åµæ¸¬æ™‚é–“
            detection_in_progress = True  # é–‹å§‹è»Šä¸»é¡¯ç¤ºè¨ˆæ™‚

    # é¡¯ç¤ºåŸå§‹ç•«é¢
    cv2.imshow("åŸå§‹æ”å½±ç•«é¢", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()